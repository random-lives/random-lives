{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Unified LLM Generation Pipeline\n",
    "\n",
    "This notebook provides an interface to the unified generation pipeline.\n",
    "All logic lives in `generation.py` - this notebook is for interactive testing and batch runs.\n",
    "\n",
    "The pipeline handles both Paleolithic and Holocene people automatically based on the sampled birth year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generation import (\n",
    "    generate_person,\n",
    "    generate_batch,\n",
    "    generate_batch_parallel,\n",
    "    # Individual steps if needed\n",
    "    generate_geography,\n",
    "    generate_demographics,\n",
    "    generate_structured_incidents,\n",
    "    generate_historical_context,\n",
    "    generate_name,\n",
    "    generate_narrative_plan,\n",
    "    generate_narrative,\n",
    "    run_pipeline,\n",
    "    reset_to_stage\n",
    ")\n",
    "from llm_utils import GenerationContext, extract_json\n",
    "\n",
    "from person import sample_year, sample_person, Person\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af725cc-4b02-48cb-89d0-a6cc6b227b63",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7190fb57-1001-47b8-a6ae-5104aa90d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 150 people...\n",
      "Generating 150 people with 50 parallel workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 150/150 [13:15<00:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 150 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''test_people = generate_batch_parallel(n=150, model=\"gpt-5.2\", workers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f998c49-c788-4f71-8e69-fe3dd14a119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading people from batch2_0100_0249.pkl...\n",
      "Found 150 people\n",
      "Removing existing markdown files from ../_lives_pending...\n",
      "  Removed 7 files\n",
      "  Exported 10 people...\n",
      "  Exported 20 people...\n",
      "  Exported 30 people...\n",
      "  Exported 40 people...\n",
      "  Exported 50 people...\n",
      "  Exported 60 people...\n",
      "  Exported 70 people...\n",
      "  Exported 80 people...\n",
      "  Exported 90 people...\n",
      "  Exported 100 people...\n",
      "  Exported 110 people...\n",
      "  Exported 120 people...\n",
      "  Exported 130 people...\n",
      "  Exported 140 people...\n",
      "  Exported 150 people...\n",
      "\n",
      "Successfully exported 150 people to ../_lives_pending\n",
      "  Index range: 0100 - 0249\n"
     ]
    }
   ],
   "source": [
    "'''with open('batch2_0100_0249.pkl', 'wb') as f:\n",
    "    dill.dump(test_people,f)\n",
    "%run export.py batch2_0100_0249.pkl --start-index 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b327f-f236-46f5-bea9-aaaa4f7fe5bb",
   "metadata": {},
   "source": [
    "# Checking existing generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b3cb1f4-ddb4-4f9e-89df-095d07d14d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('batch1_0000_0099.pkl', 'rb') as f:\n",
    "    people = dill.load(f)\n",
    "\n",
    "with open('batch2_0100_0249.pkl', 'rb') as f:\n",
    "    people += dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af42626e-7c90-4792-b2c5-a900e0d15748",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for person in people:\n",
    "    if person.lifestyle == 'Rural' and person.birth_year<1500:\n",
    "        ages += [person.age_at_death]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b461e80a-c83f-4958-8ed6-d7509979d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8f834a4-a3a4-48d7-83ad-b48eaa152b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.610294117647058"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57c80669-e5d2-42ae-9649-a1d7c6e9c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69beb79-9504-471f-b8f0-5c9e189b987f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
