{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Unified LLM Generation Pipeline\n",
    "\n",
    "This notebook provides an interface to the unified generation pipeline.\n",
    "All logic lives in `generation.py` - this notebook is for interactive testing and batch runs.\n",
    "\n",
    "The pipeline handles both Paleolithic and Holocene people automatically based on the sampled birth year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from tqdm import tqdm\n",
    "\n",
    "from generation import (\n",
    "    generate_person,\n",
    "    generate_batch,\n",
    "    generate_batch_parallel,\n",
    "    # Individual steps if needed\n",
    "    generate_geography,\n",
    "    generate_demographics,\n",
    "    generate_structured_incidents,\n",
    "    generate_historical_context,\n",
    "    generate_name,\n",
    "    generate_narrative_plan,\n",
    "    generate_narrative,\n",
    "    quality_check,\n",
    "    reset_to_stage\n",
    ")\n",
    "from llm_utils import GenerationContext, extract_json\n",
    "\n",
    "from person import sample_person, Person\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af725cc-4b02-48cb-89d0-a6cc6b227b63",
   "metadata": {},
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7190fb57-1001-47b8-a6ae-5104aa90d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# cost prio, $5.03 (prev $1.24)\\ntest_people_2 = generate_batch_parallel(n=20, model=\"gpt-5.2\", workers=20)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# cost prio, $5.03 (prev $1.24)\n",
    "test_people_2 = generate_batch_parallel(n=20, model=\"gpt-5.2\", workers=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f998c49-c788-4f71-8e69-fe3dd14a119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('test_examples_2.pkl', 'wb') as f:\\n    dill.dump(test_people_2 + olds,f)\\n%run export.py test_examples_2.pkl\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open('test_examples_2.pkl', 'wb') as f:\n",
    "    dill.dump(test_people_2 + olds,f)\n",
    "%run export.py test_examples_2.pkl'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e66b93-89f3-4ae6-ba30-7df48eb0b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_examples_2.pkl', 'rb') as f:\n",
    "       examples = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b949997-405a-4403-91a3-b7f6e21b9573",
   "metadata": {},
   "source": [
    "# Narrative Prompt Experimentation (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "wawywqi7uyg",
   "metadata": {},
   "outputs": [],
   "source": [
    "NARRATIVE_BASE_PROMPT_V2 = '''Write a narrative biography for this historical person.\n",
    "\n",
    "TASK:\n",
    "- Use the provided name\n",
    "- Weave demographic details in naturally; you don't need to include everything\n",
    "- Give names to recurring people (family, spouse, close associates); minor one-off figures can remain unnamed\n",
    "- Avoid anachronisms\n",
    "\n",
    "VOICE:\n",
    "- Plain contemporary English, no subheadings\n",
    "- Omniscient narrator: state facts confidently, no hedging (\"likely\", \"probably\", \"perhaps\", \"may have\")\n",
    "- When data presents options or ranges, make concrete choices\n",
    "- Vary sentence rhythm. Mix lengths. Fragments sometimes.\n",
    "\n",
    "TIME\n",
    "- Write as continuous narrative, not discrete blocks, following chronological order\n",
    "- Vary how you mark time passing: ages, seasons, life events, relative time, or dates. For people born before 1000 BC, prefer ages and relative time over absolute dates.\n",
    "- Discrete events should be assigned to specific times. If the narrative plan is not specific, choose an option and make the narrative specific. \n",
    "- Vary paragraph openings. Avoid too frequently beginning with temporal phrases, and avoid redundant temporal phrases\n",
    "\n",
    "PROSE STYLE:\n",
    "- Write actively and directly. State facts plainly and concretely.\n",
    "- Avoid passive, abstract, or distanced descriptions.\n",
    "- Include specific details so the reader can see what you mean.\n",
    "- No figurative language (no metaphors, similes, or personification)\n",
    "- No archaic inversions, poetic flourishes, or proverbs\n",
    "- State what happened. Do not comment on it, interpret it, or frame it poetically.\n",
    "- Do not write lines that exist to sound wise or poignant. If a sentence is reaching for literary effect, cut it or replace it with a plain one.\n",
    "- Describe what was there, not what wasn't. Avoid defining people or situations by negatives.\n",
    "\n",
    "HISTORICAL INTEGRATION:\n",
    "- Include historical framing throughout so readers can follow\n",
    "- Assume an intelligent reader who can look things up but isn't a specialist\n",
    "- Early in the narrative, briefly orient the reader to the political and cultural situation: what polity or power structure governed this area, what ethnic/linguistic group the person belonged to, and how that world related to larger historical forces. Keep it short and concrete—a sentence or two, not a paragraph of background.\n",
    "\n",
    "PERSONALITY:\n",
    "- Show traits through action, not summary\n",
    "- Do not name personality traits. Show the behavior and let the reader infer the trait.\n",
    "- Don't soften negative traits—low agreeableness causes friction, low conscientiousness causes real failures, low intelligence shows in limited understanding and poor decision-making\n",
    "\n",
    "AVOID THESE PHRASES:\n",
    "\"life went on\", \"work continued\", \"people remembered\", \"was known for\", \"in those days\", \"as was common\", \"like so many\", \"he suffered\", \"it was not X, it was Y\", \"A did not do X. A did Y\", \"no kings ruled\"\n",
    "'''\n",
    "\n",
    "HUMAN_PARTICULARITY_PROMPT_V2 = '''\n",
    "HUMAN PARTICULARITY:\n",
    "Include 2-4 specific human details that bring the person to life:\n",
    "- Friendships: Not just family/spouse, but people they chose to spend time with, who made them laugh or who they trusted\n",
    "- Small pleasures: What they enjoyed - a particular food, a time of day, a seasonal activity, hobbies, stories they told, gambling, singing, a place they liked to sit\n",
    "- Habits or routines: Morning rituals, how they did their work, where they went when troubled\n",
    "- Things that annoyed them or they avoided\n",
    "- Sources of quiet pride or satisfaction\n",
    "- Humor: Moments of teasing, jokes, laughter\n",
    "These details should feel plausible for the time, place, and personality, but must be made specific and idiosyncratic.\n",
    "'''\n",
    "\n",
    "AGE_PROMPTS_V2 = {\n",
    "    \"infant\": \"\"\"\n",
    "LENGTH: 150-300 words\n",
    "\n",
    "FOCUS:\n",
    "- The infant cannot express personality—focus on parents, household, circumstances\n",
    "- Can be told entirely from the parents' perspective\n",
    "- A few vivid details about the household and the infant's brief life\n",
    "\"\"\",\n",
    "\n",
    "    \"child\": \"\"\"\n",
    "LENGTH: 200-400 words\n",
    "\n",
    "FOCUS:\n",
    "- Personality can show in limited, age-appropriate ways (a habit, a preference, how they played)\n",
    "- Focus on a few vivid moments rather than a full arc\n",
    "- Show the household and family context\n",
    "\"\"\",\n",
    "\n",
    "    \"adolescent\": \"\"\"\n",
    "LENGTH: 400-700 words\n",
    "\n",
    "FOCUS:\n",
    "- Show emerging adult roles and relationships\n",
    "- Personality should be visible through behavior and choices\n",
    "- Include family dynamics and any work or responsibilities\n",
    "\"\"\",\n",
    "\n",
    "    \"adult\": \"\"\"\n",
    "LENGTH: 600-1000 words\n",
    "\n",
    "FOCUS:\n",
    "- Mosaic of everyday episodes\n",
    "- Include relationships and family changes\n",
    "- Show work, community, and how they navigated their world\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "ALIVE_PROMPT_V2 = \"\"\"\n",
    "ENDING:\n",
    "- End in an ordinary moment, not on a cliffhanger or dramatic note\n",
    "- The narrative must end no later than late 2025—do not project events into the future\n",
    "- End with a present-tense snapshot of their current life\n",
    "\"\"\"\n",
    "\n",
    "DEAD_PROMPT_V2 = \"\"\"\n",
    "ENDING:\n",
    "- Include the death concretely\n",
    "- Do not dwell on aftermath or sentimentalize\n",
    "- Avoid: \"breathing slowed\", \"fever rose/burned\", \"eyes closed\", \"slipped away\", \"grew weaker\", \"stopped breathing\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0uynxp6lzna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _age_category_v2(person):\n",
    "    age = person.age_at_death if person.age_at_death != \"alive\" else 30\n",
    "    if age < 3: return \"infant\"\n",
    "    if age < 11: return \"child\"\n",
    "    if age < 19: return \"adolescent\"\n",
    "    return \"adult\"\n",
    "\n",
    "def generate_narrative_v2(person, ctx):\n",
    "    age_cat = _age_category_v2(person)\n",
    "    \n",
    "    full_prompt = NARRATIVE_BASE_PROMPT_V2\n",
    "    if age_cat in [\"adolescent\", \"adult\"]:\n",
    "        full_prompt += HUMAN_PARTICULARITY_PROMPT_V2\n",
    "    full_prompt += AGE_PROMPTS_V2[age_cat]\n",
    "    full_prompt += ALIVE_PROMPT_V2 if person.is_alive() else DEAD_PROMPT_V2\n",
    "    \n",
    "    if hasattr(person, 'narrative_plan') and person.narrative_plan:\n",
    "        full_prompt += \"\\n\\nIMPORTANT: Follow the narrative plan you created earlier. Use the exact timeline for siblings, children, and incidents. The plan ensures temporal consistency.\"\n",
    "    \n",
    "    if hasattr(person, 'structured_incidents') and person.structured_incidents:\n",
    "        incidents_str = \"\\n\".join(f\"- {e.get('event', '')} ({e.get('timing', 'unknown')})\"\n",
    "                                  for e in person.structured_incidents)\n",
    "        full_prompt += \"\\n\\nPersonal incidents to incorporate:\\n\" + incidents_str\n",
    "    \n",
    "    if hasattr(person, 'historical_context') and person.historical_context:\n",
    "        context_str = \"\\n\".join(f\"- {e.get('event', '')} ({e.get('timing', 'unknown')})\"\n",
    "                                for e in person.historical_context)\n",
    "        full_prompt += \"\\n\\nHistorical context to incorporate:\\n\" + context_str\n",
    "    \n",
    "    person.messages.append({\"role\": \"user\", \"content\": full_prompt})\n",
    "    person.narrative = ctx.call(person.messages)\n",
    "    person.messages.append({\"role\": \"assistant\", \"content\": person.narrative})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775zc4n8ct8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cost Summary: gpt-5.2 ===\n",
      "Requests: 1\n",
      "Input tokens: 15,399\n",
      "  Cached: 13,952 (90.6%)\n",
      "Output tokens: 1,794\n",
      "Total cost: $0.0215\n",
      "Avg per request: 15399 in, 1794 out\n",
      "\n",
      "=== Cost Summary: gpt-5.2 ===\n",
      "Requests: 1\n",
      "Input tokens: 17,204\n",
      "  Cached: 14,976 (87.0%)\n",
      "Output tokens: 1,981\n",
      "Total cost: $0.0245\n",
      "Avg per request: 17204 in, 1981 out\n",
      "\n",
      "=== Cost Summary: gpt-5.2 ===\n",
      "Requests: 1\n",
      "Input tokens: 16,572\n",
      "  Cached: 14,976 (90.4%)\n",
      "Output tokens: 1,924\n",
      "Total cost: $0.0231\n",
      "Avg per request: 16572 in, 1924 out\n",
      "\n",
      "=== Cost Summary: gpt-5.2 ===\n",
      "Requests: 1\n",
      "Input tokens: 6,643\n",
      "  Cached: 5,760 (86.7%)\n",
      "Output tokens: 292\n",
      "Total cost: $0.0047\n",
      "Avg per request: 6643 in, 292 out\n"
     ]
    }
   ],
   "source": [
    "for person in examples[:5]:\n",
    "    reset_to_stage(person, 'narrative')\n",
    "    \n",
    "    ctx = GenerationContext(model=\"gpt-5.2\", quiet=False, show_cost=True)\n",
    "    generate_narrative_v2(person, ctx)\n",
    "    ctx.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4740b-f258-4611-af4d-fe8ffd50746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_examples_3.pkl', 'wb') as f:\n",
    "    dill.dump(examples,f)\n",
    "%run export.py test_examples_3.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b6ba9-20fd-4ff2-af5c-36b060a9a580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
